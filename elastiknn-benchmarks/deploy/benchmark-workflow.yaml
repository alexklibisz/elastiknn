apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: elastiknn-benchmark-
spec:
  entrypoint: main
  arguments:
    parameters:
      - name: driverImage
      - name: elastiknnImage
      - name: awsAccessKeyId
      - name: awsSecretAccessKey
      - name: bucket
        value: elastiknn-benchmarks
      - name: shards
        value: 1
  templates:
    - name: main
      parallelism: 1
      steps:
        - - name: generate-experiments
            template: generate-experiments
        - - name: enqueue-experiments
            template: enqueue-experiments
        - - name: apply-configmap
            template: apply-configmap
        - - name: execute-elasticsearch
            template: execute-elasticsearch
            arguments:
              parameters:
                - name: experiment
                  value: "{{item}}"
            withParam: "{{steps.enqueue-experiments.outputs.parameters.experiments}}"
#        - - name: aggregate-results
#            template: aggregate-results

    # Scala app generates experiments, writes them to s3, generates a file containing their keys, writes the file to s3.
    - name: generate-experiments
      container:
        image: "{{workflow.parameters.driverImage}}"
        imagePullPolicy: "Always"
        args:
          - com.klibisz.elastiknn.benchmarks.Generate
          - --experimentsPrefix
          - experiments
          - --bucket
          - "{{workflow.parameters.bucket}}"
          - --keysKey
          - experiments/latest.json
        env:
          - name: AWS_ACCESS_KEY_ID
            value: "{{workflow.parameters.awsAccessKeyId}}"
          - name: AWS_SECRET_ACCESS_KEY
            value: "{{workflow.parameters.awsSecretAccessKey}}"

    # Cli app copies experiments to disk so argo can generate a pod for each of the experiments.
    - name: enqueue-experiments
      container:
        image: amazon/aws-cli
        args: ["s3", "cp", "--quiet", "s3://elastiknn-benchmarks/experiments/latest.json", "/tmp/latest.json"]
        env:
          - name: AWS_ACCESS_KEY_ID
            value: "{{workflow.parameters.awsAccessKeyId}}"
          - name: AWS_SECRET_ACCESS_KEY
            value: "{{workflow.parameters.awsSecretAccessKey}}"
      outputs:
        parameters:
          - name: experiments
            valueFrom:
              path: /tmp/latest.json

    # Create a configmap mounted by the Elasticsearch sidecar containers.
    - name: apply-configmap
      resource:
        action: apply
        manifest: |
          apiVersion: v1
          kind: ConfigMap
          metadata:
            name: esconfig
          data:
            elasticsearch.yml: |
              discovery.type: single-node
              cluster.name: "no-cluster"
              node.master: true
              node.data: true
              node.ml: false
              node.ingest: false
              bootstrap.memory_lock: true
              network.host: 0.0.0.0
              node.processors: {{workflow.parameters.shards}}

    - name: execute-elasticsearch
      inputs:
        parameters:
          - name: experiment
      volumes:
        - name: esdata
          emptyDir:
            medium: Memory
        - name: esconfig
          configMap:
            name: esconfig
      securityContext:
        fsGroup: 1000 # Sets the correct permissions for mounted volume.
      # nodeSelector:
      #   beta.kubernetes.io/instance-type: m5.4xlarge
      podSpecPatch: |
        containers:
          - name: elastiknn
            resources:
              requests:
                cpu: "{{workflow.parameters.shards}}"
              limits:
                cpu: "{{workflow.parameters.shards}}"
      container:
        image: "{{workflow.parameters.driverImage}}"
        imagePullPolicy: "Always"
        args:
          - com.klibisz.elastiknn.benchmarks.Execute
          - --experimentKey
          - "{{inputs.parameters.experiment}}"
          - --datasetsPrefix
          - "data/processed"
          - --resultsPrefix
          - "results/raw"
          - --bucket
          - "{{workflow.parameters.bucket}}"
          - --maxQueries
          - "1000"
          - --shards
          - "{{workflow.parameters.shards}}"
        env:
          - name: AWS_ACCESS_KEY_ID
            value: "{{workflow.parameters.awsAccessKeyId}}"
          - name: AWS_SECRET_ACCESS_KEY
            value: "{{workflow.parameters.awsSecretAccessKey}}"
          - name: JAVA_OPTS
            value: >-
              -XX:MinRAMPercentage=10
              -XX:MaxRAMPercentage=90
              -XX:+HeapDumpOnOutOfMemoryError
              -XX:+ExitOnOutOfMemoryError
        resources:
          requests:
            cpu: 1
            memory: 2G
          limits:
            cpu: 1
            memory: 2G
      sidecars:
        - name: elastiknn
          image: "{{workflow.parameters.elastiknnImage}}"
          imagePullPolicy: "Always"
          env:
            # Setting memory > 4G seems to cause high garbage collection.
            - name: ES_JAVA_OPTS
              value: >-
                -Xms4G -Xmx4G
                -Dcom.sun.management.jmxremote.ssl=false
                -Dcom.sun.management.jmxremote.authenticate=false
                -Dcom.sun.management.jmxremote.local.only=false
                -Dcom.sun.management.jmxremote.port=8097
                -Dcom.sun.management.jmxremote.rmi.port=8097
                -Djava.rmi.server.hostname=localhost
          ports:
            - name: jmx
              containerport: 8097
              protocol: TCP
          volumeMounts:
            - name: esdata
              mountPath: /usr/share/elasticsearch/data
              readOnly: false
            - name: esconfig
              mountPath: /usr/share/elasticsearch/config/elasticsearch.yml
              subPath: elasticsearch.yml
              readOnly: true
          resources:
            requests:
              memory: 10G
            limits:
              memory: 10G

    - name: aggregate-results
      container:
        image: "{{workflow.parameters.driverImage}}"
        imagePullPolicy: "Always"
        env:
          - name: AWS_ACCESS_KEY_ID
            value: "{{workflow.parameters.awsAccessKeyId}}"
          - name: AWS_SECRET_ACCESS_KEY
            value: "{{workflow.parameters.awsSecretAccessKey}}"
        args:
          - com.klibisz.elastiknn.benchmarks.Aggregate
          - --resultsBucket
          - elastiknn-benchmarks
          - --resultsPrefix
          - results/raw
          - --aggregateBucket
          - elastiknn-benchmarks
          - --aggregateKey
          - results/aggregate/aggregate.csv
